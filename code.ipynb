{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:00:14.471788Z",
     "iopub.status.busy": "2025-11-26T16:00:14.470925Z",
     "iopub.status.idle": "2025-11-26T16:00:14.474963Z",
     "shell.execute_reply": "2025-11-26T16:00:14.474256Z",
     "shell.execute_reply.started": "2025-11-26T16:00:14.471753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# GDRIVE_ID_DATA = \"1ONRQ36PFPnYNA4R6ZlmM7UQJ4LiAzEH0\"\n",
    "# !gdown $GDRIVE_ID_DATA -O Arabic-Text-Diacritization.zip\n",
    "# !unzip Arabic-Text-Diacritization.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Arabic letters and diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:09:14.506351Z",
     "iopub.status.busy": "2025-11-26T16:09:14.505803Z",
     "iopub.status.idle": "2025-11-26T16:09:14.511024Z",
     "shell.execute_reply": "2025-11-26T16:09:14.510226Z",
     "shell.execute_reply.started": "2025-11-26T16:09:14.506323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Configuration for Kaggle\n",
    "Check GPU availability and configure TensorFlow to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:00:18.118960Z",
     "iopub.status.busy": "2025-11-26T16:00:18.118691Z",
     "iopub.status.idle": "2025-11-26T16:00:18.125503Z",
     "shell.execute_reply": "2025-11-26T16:00:18.124653Z",
     "shell.execute_reply.started": "2025-11-26T16:00:18.118938Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "No GPU found. Training will use CPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Get GPU details\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to avoid OOM errors\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        print(f\"GPU detected: {gpus}\")\n",
    "        print(f\"GPU Name: {tf.test.gpu_device_name()}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found. Training will use CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:00:22.440725Z",
     "iopub.status.busy": "2025-11-26T16:00:22.440119Z",
     "iopub.status.idle": "2025-11-26T16:00:22.446751Z",
     "shell.execute_reply": "2025-11-26T16:00:22.445974Z",
     "shell.execute_reply.started": "2025-11-26T16:00:22.440700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "arabic_letters = []\n",
    "diacritics = []\n",
    "diacritics_to_id = {}\n",
    "with open('./utils/arabic_letters.pickle', 'rb') as f:\n",
    "    arabic_letters = pickle.load(f)\n",
    "with open('./utils/diacritics.pickle', 'rb') as f:\n",
    "    diacritics = pickle.load(f)\n",
    "with open('./utils/diacritic2id.pickle', 'rb') as f:\n",
    "    diacritics_to_id = pickle.load(f)\n",
    "\n",
    "arabic_letters_sorted = sorted(arabic_letters)\n",
    "char_to_id = {char: idx + 1 for idx, char in enumerate(arabic_letters_sorted)}\n",
    "char_to_id['<PAD>'] = 0\n",
    "char_to_id['UNK'] = len(char_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dictionaries and Create Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Read train and val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:42:21.867722Z",
     "iopub.status.busy": "2025-11-26T14:42:21.867488Z",
     "iopub.status.idle": "2025-11-26T14:42:22.056003Z",
     "shell.execute_reply": "2025-11-26T14:42:22.055417Z",
     "shell.execute_reply.started": "2025-11-26T14:42:21.867702Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "with open('./data/train.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        train_data.append(line.strip())\n",
    "with open('./data/val.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        val_data.append(line.strip())\n",
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:42:22.057548Z",
     "iopub.status.busy": "2025-11-26T14:42:22.057282Z",
     "iopub.status.idle": "2025-11-26T14:42:22.061876Z",
     "shell.execute_reply": "2025-11-26T14:42:22.061144Z",
     "shell.execute_reply.started": "2025-11-26T14:42:22.057531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_arabic_text(text):\n",
    "    \"\"\"\n",
    "    Clean text to keep only Arabic letters, diacritics, and spaces\n",
    "    \"\"\"\n",
    "    # Create a set of allowed characters (Arabic letters + diacritics + space)\n",
    "    allowed_chars = arabic_letters.union(diacritics, {' ', '\\t', '\\n'})\n",
    "    \n",
    "    # Filter the text to keep only allowed characters\n",
    "    cleaned_text = ''.join(char for char in text if char in allowed_chars)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:42:22.062899Z",
     "iopub.status.busy": "2025-11-26T14:42:22.062667Z",
     "iopub.status.idle": "2025-11-26T14:42:26.293937Z",
     "shell.execute_reply": "2025-11-26T14:42:26.293346Z",
     "shell.execute_reply.started": "2025-11-26T14:42:22.062874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data_witout_diacritics = []\n",
    "val_data_witout_diacritics = []\n",
    "for i in range(len(train_data)):\n",
    "    train_data[i] = clean_arabic_text(train_data[i])\n",
    "    train_data_witout_diacritics.append(araby.strip_diacritics(train_data[i]))\n",
    "for i in range(len(val_data)):\n",
    "    val_data[i] = clean_arabic_text(val_data[i])\n",
    "    val_data_witout_diacritics.append(araby.strip_diacritics(val_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:42:26.296124Z",
     "iopub.status.busy": "2025-11-26T14:42:26.295649Z",
     "iopub.status.idle": "2025-11-26T14:42:26.300721Z",
     "shell.execute_reply": "2025-11-26T14:42:26.300019Z",
     "shell.execute_reply.started": "2025-11-26T14:42:26.296105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def is_diacritic(ch):\n",
    "    # Unicode combining marks (Arabic diacritics are combining marks)\n",
    "    return unicodedata.combining(ch) != 0\n",
    "\n",
    "def extract_base_and_diacritics(text):\n",
    "    # normalize to NFC so base+combining marks are consistent\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    bases = []\n",
    "    diacs = []\n",
    "    current_base = None\n",
    "    current_diac = ''\n",
    "    for ch in text:\n",
    "        if is_diacritic(ch):\n",
    "            # accumulate diacritics for current base\n",
    "            current_diac += ch\n",
    "        else:\n",
    "            # new base character\n",
    "            if current_base is not None:\n",
    "                bases.append(current_base)\n",
    "                diacs.append(current_diac)\n",
    "            current_base = ch\n",
    "            current_diac = ''\n",
    "    # append last\n",
    "    if current_base is not None:\n",
    "        bases.append(current_base)\n",
    "        diacs.append(current_diac)\n",
    "    return bases, diacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:42:26.301783Z",
     "iopub.status.busy": "2025-11-26T14:42:26.301460Z",
     "iopub.status.idle": "2025-11-26T14:42:32.581555Z",
     "shell.execute_reply": "2025-11-26T14:42:32.580969Z",
     "shell.execute_reply.started": "2025-11-26T14:42:26.301760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m UNKNOWN_DIACRITIC_ID \u001b[38;5;241m=\u001b[39m diacritics_to_id\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(diacritics_to_id) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[1;32m----> 9\u001b[0m     bases, diacs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_base_and_diacritics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# convert letters to IDs\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     x_train_raw\u001b[38;5;241m.\u001b[39mappend([char_to_id\u001b[38;5;241m.\u001b[39mget(c, char_to_id[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNK\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m bases])\n",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m, in \u001b[0;36mextract_base_and_diacritics\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     20\u001b[0m             diacs\u001b[38;5;241m.\u001b[39mappend(current_diac)\n\u001b[0;32m     21\u001b[0m         current_base \u001b[38;5;241m=\u001b[39m ch\n\u001b[1;32m---> 22\u001b[0m         current_diac \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# append last\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare training data - extract characters and their diacritics\n",
    "x_train_raw = []\n",
    "y_train_raw = []\n",
    "\n",
    "# Use a constant for unknown diacritic instead of hardcoded value\n",
    "UNKNOWN_DIACRITIC_ID = diacritics_to_id.get('', len(diacritics_to_id) - 1)\n",
    "\n",
    "for text in train_data:\n",
    "    bases, diacs = extract_base_and_diacritics(text)\n",
    "    # convert letters to IDs\n",
    "    x_train_raw.append([char_to_id.get(c, char_to_id['UNK']) for c in bases])\n",
    "    y_train_raw.append([diacritics_to_id.get(d, UNKNOWN_DIACRITIC_ID) for d in diacs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:42:32.582514Z",
     "iopub.status.busy": "2025-11-26T14:42:32.582283Z",
     "iopub.status.idle": "2025-11-26T14:42:32.613906Z",
     "shell.execute_reply": "2025-11-26T14:42:32.613193Z",
     "shell.execute_reply.started": "2025-11-26T14:42:32.582488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(char_to_id)\n",
    "num_diacritics = len(diacritics_to_id)\n",
    "\n",
    "model = models.Sequential([\n",
    "    # TRAINABLE EMBEDDINGS (THIS LAYER LEARNS)\n",
    "    layers.Embedding(input_dim=vocab_size,\n",
    "                     output_dim=128,     # embedding size (trainable)\n",
    "                     mask_zero=True),\n",
    "\n",
    "    # BiLSTM for sequence modeling\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
    "\n",
    "    # Predict diacritic for each character - use Dense directly instead of TimeDistributed\n",
    "    layers.Dense(num_diacritics, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:42:32.614775Z",
     "iopub.status.busy": "2025-11-26T14:42:32.614592Z",
     "iopub.status.idle": "2025-11-26T14:42:34.461485Z",
     "shell.execute_reply": "2025-11-26T14:42:34.460857Z",
     "shell.execute_reply.started": "2025-11-26T14:42:32.614760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 7095)\n",
      "y_train shape: (50000, 7095)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences to same length\n",
    "PAD_DIACRITIC_ID = diacritics_to_id.get('', 0)  # Use empty string diacritic for padding\n",
    "\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train_raw, padding='post', value=0)\n",
    "y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train_raw, padding='post', value=PAD_DIACRITIC_ID)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:42:34.462518Z",
     "iopub.status.busy": "2025-11-26T14:42:34.462210Z",
     "iopub.status.idle": "2025-11-26T15:31:15.645077Z",
     "shell.execute_reply": "2025-11-26T15:31:15.644274Z",
     "shell.execute_reply.started": "2025-11-26T14:42:34.462499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Train model on GPU\n",
    "# with tf.device('/GPU:0'):\n",
    "#     history = model.fit(x_train, y_train, epochs=20, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:09:21.317266Z",
     "iopub.status.busy": "2025-11-26T16:09:21.316625Z",
     "iopub.status.idle": "2025-11-26T16:09:21.394527Z",
     "shell.execute_reply": "2025-11-26T16:09:21.393959Z",
     "shell.execute_reply.started": "2025-11-26T16:09:21.317240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# joblib.dump(model, \"/kaggle/working/model1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:00:40.152198Z",
     "iopub.status.busy": "2025-11-26T16:00:40.151894Z",
     "iopub.status.idle": "2025-11-26T16:00:40.450841Z",
     "shell.execute_reply": "2025-11-26T16:00:40.450291Z",
     "shell.execute_reply.started": "2025-11-26T16:00:40.152175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare validation data\n",
    "x_val_raw = []\n",
    "y_val_raw = []\n",
    "\n",
    "for text in val_data:\n",
    "    bases, diacs = extract_base_and_diacritics(text)\n",
    "    # convert letters to IDs\n",
    "    x_val_raw.append([char_to_id.get(c, char_to_id['UNK']) for c in bases])\n",
    "    y_val_raw.append([diacritics_to_id.get(d, UNKNOWN_DIACRITIC_ID) for d in diacs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:00:41.449125Z",
     "iopub.status.busy": "2025-11-26T16:00:41.448813Z",
     "iopub.status.idle": "2025-11-26T16:00:41.520970Z",
     "shell.execute_reply": "2025-11-26T16:00:41.520355Z",
     "shell.execute_reply.started": "2025-11-26T16:00:41.449066Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val shape: (2500, 1172)\n",
      "y_val shape: (2500, 1172)\n"
     ]
    }
   ],
   "source": [
    "# Pad validation sequences\n",
    "x_val = tf.keras.preprocessing.sequence.pad_sequences(x_val_raw, padding='post', value=0)\n",
    "y_val = tf.keras.preprocessing.sequence.pad_sequences(y_val_raw, padding='post', value=PAD_DIACRITIC_ID)\n",
    "\n",
    "print(f\"x_val shape: {x_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:00:42.981051Z",
     "iopub.status.busy": "2025-11-26T16:00:42.980375Z",
     "iopub.status.idle": "2025-11-26T16:00:45.549444Z",
     "shell.execute_reply": "2025-11-26T16:00:45.548815Z",
     "shell.execute_reply.started": "2025-11-26T16:00:42.981027Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 331ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:00:46.669238Z",
     "iopub.status.busy": "2025-11-26T16:00:46.668617Z",
     "iopub.status.idle": "2025-11-26T16:00:46.799396Z",
     "shell.execute_reply": "2025-11-26T16:00:46.798764Z",
     "shell.execute_reply.started": "2025-11-26T16:00:46.669213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.0287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
    "y_true = y_val\n",
    "accuracy = accuracy_score(y_true.flatten(), y_pred_classes.flatten())\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"./models/LSTM.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:17:02.434865Z",
     "iopub.status.busy": "2025-11-26T16:17:02.434231Z",
     "iopub.status.idle": "2025-11-26T16:17:02.439537Z",
     "shell.execute_reply": "2025-11-26T16:17:02.438786Z",
     "shell.execute_reply.started": "2025-11-26T16:17:02.434841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_model(test_sent):\n",
    "    test_sent.strip()\n",
    "    x_test_raw, y_test_raw = [], []\n",
    "    bases_test, diacs_test = extract_base_and_diacritics(test_sent)\n",
    "    x_test_raw.append([char_to_id.get(c, char_to_id['UNK']) for c in bases_test])\n",
    "    return x_test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:17:09.024013Z",
     "iopub.status.busy": "2025-11-26T16:17:09.023262Z",
     "iopub.status.idle": "2025-11-26T16:17:09.031404Z",
     "shell.execute_reply": "2025-11-26T16:17:09.030352Z",
     "shell.execute_reply.started": "2025-11-26T16:17:09.023978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def merge(x_test, y_pred_classes, char_to_id, diacritics_to_id):\n",
    "    \"\"\"\n",
    "    Merge character sequences with predicted diacritics to reconstruct text\n",
    "    \n",
    "    Args:\n",
    "        x_test: numpy array of character IDs (samples × sequence_length)\n",
    "        y_pred_classes: numpy array of predicted diacritic IDs (samples × sequence_length)\n",
    "        char_to_id: dictionary mapping characters to IDs\n",
    "        diacritics_to_id: dictionary mapping diacritics to IDs\n",
    "    \n",
    "    Returns:\n",
    "        List of reconstructed diacritized text strings\n",
    "    \"\"\"\n",
    "    # Create reverse mappings\n",
    "    id_to_char = {v: k for k, v in char_to_id.items()}\n",
    "    id_to_diacritic = {v: k for k, v in diacritics_to_id.items()}\n",
    "    \n",
    "    reconstructed_texts = []\n",
    "    \n",
    "    # Process each sample\n",
    "    for char_seq, diac_seq in zip(x_test, y_pred_classes):\n",
    "        text = \"\"\n",
    "        \n",
    "        for char_id, diac_id in zip(char_seq, diac_seq):\n",
    "            # Skip padding\n",
    "            if char_id == 0:  # PAD character\n",
    "                break\n",
    "            \n",
    "            # Get character\n",
    "            char = id_to_char.get(char_id, '')\n",
    "            \n",
    "            # Get diacritic\n",
    "            diacritic = id_to_diacritic.get(diac_id, '')\n",
    "            \n",
    "            # Combine character with diacritic\n",
    "            text += char + diacritic\n",
    "        \n",
    "        text = text.replace(\"UNK\", \" \")\n",
    "        reconstructed_texts.append(text)\n",
    "    \n",
    "    return reconstructed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:17:04.153979Z",
     "iopub.status.busy": "2025-11-26T16:17:04.153348Z",
     "iopub.status.idle": "2025-11-26T16:17:04.432609Z",
     "shell.execute_reply": "2025-11-26T16:17:04.431924Z",
     "shell.execute_reply.started": "2025-11-26T16:17:04.153949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n"
     ]
    }
   ],
   "source": [
    "test_sent = \"هذا نص تجريبي لاختبار نموذج تشكيل النص العربي.\"\n",
    "\n",
    "x_test = test_model(test_sent)\n",
    "y_test_pred = model.predict(np.array(x_test))\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:17:05.834779Z",
     "iopub.status.busy": "2025-11-26T16:17:05.833959Z",
     "iopub.status.idle": "2025-11-26T16:17:05.839512Z",
     "shell.execute_reply": "2025-11-26T16:17:05.838830Z",
     "shell.execute_reply.started": "2025-11-26T16:17:05.834741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 703, 15)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قَوْلُهُ وَلَوْ ادعَى وَلَدَ أَمَةٍ مُشْتَرِكَةٍ ثَبَتَ نَسَبُهُ وَهِيَ أُم وَلَدِهِ وَلَزِمَهُ نِصْفُ قِيمَتِهَا وَنِصْفَ عُقْرِهَا لَا قِيمَتُهُ أَما ثُبُوتُ النسَبِ فَلِأَنهُ لَما ثَبَتَ فِي نِصْفِهِ لِمُصَادَفَتِهِ مِلْكَهُ ثَبَتَ فِي الْبَاقِي ضَرُورَةً أَنهُ لَا يَتَجَزأُ لِمَا أَن سَبَبَهُ لَا يَتَجَزأُ وَهُوَ الْعُلُوقُ إذْ الْوَلَدُ الْوَاحِدُ لَا يُعَلَقُ مِنْ مَاءَيْنِ وَأَما صَيْرُورَتُهَا أُم وَلَدٍ فَلِأَن الِاسْتِيلَادَ لَا يَتَجَزأُ عِنْدَهُ وَعِنْدَهُمَا يَصِيرُ نَصِيبَهُ أُم وَلَدٍ لَهُ ثُم يَتَمَلكُ نَصِيبَ صَاحِبِهِ إذْ هُوَ قَابِلٌ لِلْمِلْكِ وَأَما ضَمَانُ نِصْفِ الْقِيمَةِ فَلِأَنهُ تَمْلكُ نَصِيبَ صَاحِبِهِ لِمَا اسْتَكْمَلَ الِاسْتِيلَادُ وَأَما ضَمَانُ نِصْفِ الْعُقْرِ فَلِأَنهُ وَطِئَ جَارِيَةً مُشْتَرِكَةٍ إذْ الْمِلْكُ ثَبَتَ حُكْمًا لِلِاسْتِيلَادِ فَيَعْقِبُهُ الْمِلْكُ فِي نَصِيبِ صَاحِبِهِ بِخِلَافِ الْأَبِ إذَا اسْتَوَلَدَ جَارِيَةَ ابْنِهِ لِأَن الْمِلْكَ هُنَاكَ ثَبَتَ شَرْطًا لِلِاسْتِيلَادِ فَيَتَقَدمُهُ فَصَارَ وَاطِئًا مِلْكَ نَفْسِهِ وَأَما عَدَمُ ضَمَانِ قِيمَةِ الْوَلَدِ فَلِأَن النسَبَ يَثْبُتُ مُسْتَنِدًا إلَى وَقْتِ الْعُلُوقِ فَلَمْ يَتَعَلقْ شَيْءٌ مِنْهُ عَلَى مِلْكِ شَرِيكِهِ\n"
     ]
    }
   ],
   "source": [
    "output_sentences = merge(x_test, y_test_pred_classes, char_to_id, diacritics_to_id)[0]\n",
    "print(output_sentences)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "IP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

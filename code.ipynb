{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9ba446",
   "metadata": {},
   "source": [
    "<h1> Arabic letters and diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "255d0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6db63735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ل', 'ظ', 'ث', 'أ', 'ي', 'ك', 'ء', 'غ', 'ر', 'ن', 'ة', 'ق', 'س', 'ا', 'ج', 'ص', 'ئ', 'ت', 'م', 'د', 'و', 'ع', 'خ', 'ذ', 'إ', 'ى', 'ب', 'ز', 'ض', 'ف', 'آ', 'ح', 'ه', 'ؤ', 'ش', 'ط'}\n",
      "{'َ', 'ّ', 'ٌ', 'ٍ', 'ْ', 'ُ', 'ً', 'ِ'}\n",
      "{'َ': 0, 'ً': 1, 'ُ': 2, 'ٌ': 3, 'ِ': 4, 'ٍ': 5, 'ْ': 6, 'ّ': 7, 'َّ': 8, 'ًّ': 9, 'ُّ': 10, 'ٌّ': 11, 'ِّ': 12, 'ٍّ': 13, '': 14}\n"
     ]
    }
   ],
   "source": [
    "arabic_letters = []\n",
    "diacritics = []\n",
    "diacritics_to_id = {}\n",
    "with open('./utils/arabic_letters.pickle', 'rb') as f:\n",
    "    arabic_letters = pickle.load(f)\n",
    "with open('./utils/diacritics.pickle', 'rb') as f:\n",
    "    diacritics = pickle.load(f)\n",
    "with open('./utils/diacritic2id.pickle', 'rb') as f:\n",
    "    diacritics_to_id = pickle.load(f)\n",
    "\n",
    "print(arabic_letters)\n",
    "print(diacritics)\n",
    "print(diacritics_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d234883",
   "metadata": {},
   "source": [
    "<h2> Read train and val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3259f61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "with open('./data/train.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        train_data.append(line.strip())\n",
    "with open('./data/val.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        val_data.append(line.strip())\n",
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb6e3d9",
   "metadata": {},
   "source": [
    "<h2> Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32342b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_arabic_text(text):\n",
    "    \"\"\"\n",
    "    Clean text to keep only Arabic letters, diacritics, and spaces\n",
    "    \"\"\"\n",
    "    # Create a set of allowed characters (Arabic letters + diacritics + space)\n",
    "    allowed_chars = arabic_letters.union(diacritics, {' ', '\\t', '\\n'})\n",
    "    \n",
    "    # Filter the text to keep only allowed characters\n",
    "    cleaned_text = ''.join(char for char in text if char in allowed_chars)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4618259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_data)):\n",
    "    train_data[i] = clean_arabic_text(train_data[i])\n",
    "for i in range(len(val_data)):\n",
    "    val_data[i] = clean_arabic_text(val_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ee5d0",
   "metadata": {},
   "source": [
    "<h2> Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_data = []\n",
    "for sentence in train_data:\n",
    "    tokenized_train_data.append(araby.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c849ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['وَلَوْ', 'جَمَعَ', 'ثُمَّ', 'عَلِمَ', 'تَرْكَ', 'رُكْنٍ', 'مِنْ', 'الْأُولَى', 'بَطَلَتَا', 'وَيُعِيدُهُمَا', 'جَامِعًا', 'أَوْ', 'مِنْ', 'الثَّانِيَةِ', 'فَإِنْ', 'لَمْ', 'يَطُلْ', 'تَدَارَكَ', 'وَإِلَّا', 'فَبَاطِلَةٌ', 'وَلَا', 'جَمَعَ', 'وَلَوْ', 'جَهِلَ', 'أَعَادَهُمَا', 'لِوَقْتَيْهِمَا']\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
